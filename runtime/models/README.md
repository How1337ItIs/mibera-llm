# Model Downloads

High-quality GGUF models will be uploaded here via Git LFS.

## Expected Models:
- `mibera-Q4_K_M.gguf` (8.5GB) - **Recommended for RTX 3080**
- `mibera-Q3_K_M.gguf` (6.9GB) - Good quality, faster
- `mibera-f16.gguf` (26GB) - Best quality (requires 32GB+ RAM)

## Download:
```bash
git lfs pull
```

Models will be generated and uploaded once remote conversion is set up.